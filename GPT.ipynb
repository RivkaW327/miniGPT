{"cells":[{"cell_type":"code","execution_count":null,"id":"efa48898-0bdb-4e55-b249-a62959f80560","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["c49b1c25f7b44b14a2fc7922e9950bed","ef5873517074452486fc197c90da66e9","e8fdffe37594482e8bd1aa930dc0a586","1a8f049017cd45179b5908869bb8d1b5","8cecdc8a0cf24c9f9203905976159e42","c86f59e6cb53488d8ad2ce005c826b04","1c1d3e51d33e4aa18acae92a5fbf5352","d7a7dbcaba764b7181dccf8383efa4cf","b2e0869168934d9aba17640641f801d4","3e8ecd89f92f4db880a8bbc44a49a068","c3dbf5d9a7b140f2b18599b86f6d046c"]},"executionInfo":{"elapsed":88174,"status":"ok","timestamp":1740878644122,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"},"user_tz":-120},"id":"efa48898-0bdb-4e55-b249-a62959f80560","outputId":"e4e84eb4-c328-4850-cb16-f6838545c754"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c49b1c25f7b44b14a2fc7922e9950bed","version_major":2,"version_minor":0},"text/plain":["Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# # !pip install datasets\n","# from datasets import load_dataset\n","# dataset = load_dataset(\"Skylion007/openwebtext\")\n"]},{"cell_type":"code","execution_count":2,"id":"LJlmUCFuK3_-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3914,"status":"ok","timestamp":1743977924073,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"},"user_tz":-180},"id":"LJlmUCFuK3_-","outputId":"0ce66cb3-6a9c-40e3-ca2e-2faa292a18db"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import mmap\n","import random\n","import pickle\n","# import argparse\n","\n","# parser = argparse.ArgumentParser(description=\"this is demo program\")\n","# parser.add_argument('-batch_size', type=str, required=True, help=\"please provide a batch size\")\n","\n","# args = parser.parse_args()\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","batch_size = 64 # args.batch_size\n","block_size = 128\n","max_iters = 3000\n","learning_rate = 3e-4 #3e-3, 3e-4, 1e-3, 1e-4\n","eval_iters = 500\n","n_embd = 384\n","n_head = 8\n","n_layers = 8\n","dropout = 0.2"]},{"cell_type":"code","execution_count":3,"id":"VcirnVDbVamd","metadata":{"executionInfo":{"elapsed":32992,"status":"ok","timestamp":1743977957060,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"},"user_tz":-180},"id":"VcirnVDbVamd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"887a4534-6c40-4d89-fc70-242ab7a4edbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"id":"5ca41e80-9e18-471a-8232-ff5256b1547a","metadata":{"id":"5ca41e80-9e18-471a-8232-ff5256b1547a","executionInfo":{"status":"ok","timestamp":1743977958723,"user_tz":-180,"elapsed":1669,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}}},"outputs":[],"source":["chars =\"\"\n","with open('/content/drive/MyDrive/create_gpt/openwebtext/vocab.txt' , 'r', encoding='utf-8') as f:\n","    text = f.read()\n","    chars = sorted(list(set(text)))\n","\n","vocab_size = len(chars)\n"]},{"cell_type":"code","execution_count":5,"id":"914970e7","metadata":{"id":"914970e7","executionInfo":{"status":"ok","timestamp":1743977958723,"user_tz":-180,"elapsed":3,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}}},"outputs":[],"source":["#very  simple character level tokenizer\n","string_to_int = {ch:i for i,ch in enumerate(chars)}\n","int_to_string = {i:ch for i,ch in enumerate(chars)}\n","encode = lambda s: [string_to_int[c] for c in s]\n","decode = lambda l:''.join([int_to_string[i] for i in l])"]},{"cell_type":"code","execution_count":6,"id":"663a0f52-e50f-4bd1-95f1-0b837d5b6f19","metadata":{"id":"663a0f52-e50f-4bd1-95f1-0b837d5b6f19","executionInfo":{"status":"ok","timestamp":1743977960016,"user_tz":-180,"elapsed":1295,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}}},"outputs":[],"source":["def get_random_chunk(split):\n","    filename = \"/content/drive/MyDrive/create_gpt/openwebtext/train_split.txt\" if split == 'train' else \"/content/drive/MyDrive/create_gpt/openwebtext/val_split.txt\"\n","    with open(filename, 'rb') as f:\n","        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n","            # Determine the file size and a random position to start reading\n","            file_size = len(mm)\n","            start_pos = random.randint(0, (file_size) -block_size*batch_size)\n","\n","            # Seek to the random position and read the block of text\n","            mm.seek(start_pos)\n","            block = mm.read(block_size*batch_size-1)\n","\n","            # Decode the block to a string, ignoring any invalid byte sequences\n","            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r','')\n","\n","            # Train and test splits\n","            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n","\n","    return data\n","\n","def get_batch(split):\n","    data = get_random_chunk(split)\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch. stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","\n","x, y =get_batch('train')"]},{"cell_type":"code","execution_count":7,"id":"0yfiGxw2jOQV","metadata":{"id":"0yfiGxw2jOQV","executionInfo":{"status":"ok","timestamp":1743977960016,"user_tz":-180,"elapsed":8,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}}},"outputs":[],"source":["\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"code","execution_count":8,"id":"sBKDvE7GTb4N","metadata":{"id":"sBKDvE7GTb4N","executionInfo":{"status":"ok","timestamp":1743977966921,"user_tz":-180,"elapsed":6912,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9978599-e684-4224-a7d1-c5113767767b"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading model parameters.......\n","loaded successfully!\n"]}],"source":["class Head(nn.Module):\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","      #input of size (batch , time-step, channels)\n","      #output of size (batch, time-step, head size)\n","        B,T,C = x.shape\n","        k = self.key(x) #(B, T, hs)\n","        q = self.query(x) #(B, T, hs)\n","        #compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * k.shape[-1] **-0.5 #(B, T, hs) @ (B,hs,T) --> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) #(B, T, T)\n","        wei = F.softmax(wei, dim=-1) #(B, T, T)\n","        wei = self.dropout(wei)\n","        #performe the weight aggregation of the values\n","        v = self.value(x) #(B, T, hs)\n","        out = wei @ v # (B, T, T) @ (B, T, hs) --> (B, T, hs)\n","        return out\n","\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1) #(B, T, F)\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, n_embd, n_head):\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedForward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","\n","    def forward(self, x):\n","        y = self.sa(x)\n","        x = self.ln1(x + y)\n","        y = self.ffwd(x)\n","        x = self.ln2(x + y)\n","        return x\n","\n","class GPTLanguageModel(nn.Module):\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        self.block = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layers)])\n","        self.ln_f = nn.LayerNorm(n_embd)\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, index, targets=None):\n","        B, T = index.shape\n","\n","        # index and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(index) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B, T,CI\n","        x = self.block(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T, vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, index, max_new_tokens):\n","        for _ in range(max_new_tokens):\n","            index_cond = index if index.shape[1] < block_size else index[:, -block_size:]\n","            logits, loss = self.forward(index_cond)\n","            logits = logits[:, -1, :] if logits.shape[1] > 0 else logits[:, 0, :]\n","            probs = F.softmax(logits, dim =- 1)\n","            index_next = torch.multinomial(probs, num_samples=1)\n","            index = torch.cat((index_cond, index_next), dim=1)\n","        return index\n","\n","model = GPTLanguageModel(vocab_size)\n","print(\"loading model parameters.......\")\n","with open('/content/drive/MyDrive/create_gpt/model_state.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","    print(\"loaded successfully!\")\n","m = model.to(device)\n"]},{"cell_type":"code","execution_count":13,"id":"fgrLAzm_XHb8","metadata":{"id":"fgrLAzm_XHb8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743980850569,"user_tz":-180,"elapsed":2530960,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}},"outputId":"6cb9a531-56a4-4b46-9bcf-e87a4c1ebe7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["step: 0, train loss: 1.4057, val loss: 1.4085\n","step: 500, train loss: 1.4016, val loss: 1.3820\n","step: 1000, train loss: 1.3734, val loss: 1.4076\n","step: 1500, train loss: 1.3707, val loss: 1.3417\n","step: 2000, train loss: 1.3407, val loss: 1.3615\n","step: 2500, train loss: 1.3639, val loss: 1.3226\n","1.4215856790542603\n","model saved\n"]}],"source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","    if iter % eval_iters == 0:\n","        losses = estimate_loss()\n","        print(f\"step: {iter}, train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n","\n","    # sample a batch of data\n","    xb, yb = get_batch('train')\n","\n","    # evaluate the loss\n","    logits, loss = model.forward(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","print(loss.item())\n","\n","\n","with open('/content/drive/MyDrive/create_gpt/model_state.pkl', 'wb') as f:\n","    pickle.dump(model, f)\n","    print(\"model saved\")"]},{"cell_type":"code","execution_count":15,"id":"8p1zRgYsdlpa","metadata":{"id":"8p1zRgYsdlpa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743980994416,"user_tz":-180,"elapsed":20960,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}},"outputId":"c30f9f5c-bafc-43cc-ce9e-a49e2283abde"},"outputs":[{"output_type":"stream","name":"stdout","text":["prompt:\n","hello my name is rivki\n","Completion:\n","hello my name is rivking to the investors. His college is a warning past (iron) in Jasan standoco-------------------------\n"]}],"source":["prompt = input(\"prompt:\\n\")\n","context = torch.tensor(encode(prompt), dtype = torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens = 100)[0].tolist())\n","print(f\"Completion:\\n{generated_chars}\")"]},{"cell_type":"code","execution_count":11,"id":"592a8d25-122b-4068-8f42-c91b8ed17c3c","metadata":{"id":"592a8d25-122b-4068-8f42-c91b8ed17c3c","executionInfo":{"status":"ok","timestamp":1743978038498,"user_tz":-180,"elapsed":4,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}}},"outputs":[],"source":["@torch.no_grad()\n","def evaluate_metrics(split='val'):\n","    model.eval()\n","    total_loss = 0.0\n","    total_tokens = 0\n","    total_correct = 0\n","\n","    for _ in range(eval_iters):\n","        X, Y = get_batch(split)\n","        logits, loss = model(X, Y)\n","        total_loss += loss.item() * Y.numel()\n","        total_tokens += Y.numel()\n","\n","        # Reshape preds to match Y's shape before comparison\n","        preds = torch.argmax(logits, dim=-1).view(Y.shape) # Reshape preds to match Y's shape\n","\n","        correct = (preds == Y).float()\n","        total_correct += correct.sum().item()\n","\n","    avg_loss = total_loss / total_tokens\n","    accuracy = total_correct / total_tokens\n","    perplexity = torch.exp(torch.tensor(avg_loss))\n","\n","    return {\n","        'loss': avg_loss,\n","        'accuracy': accuracy,\n","        'perplexity': perplexity.item()\n","    }"]},{"cell_type":"code","source":["metrics = evaluate_metrics('val')\n","print(f\"val loss: {metrics['loss']:.4f}, accuracy: {metrics['accuracy']:.4f}, perplexity: {metrics['perplexity']:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Svf67dAsLkJe","executionInfo":{"status":"ok","timestamp":1743980924223,"user_tz":-180,"elapsed":66379,"user":{"displayName":"רבקי ולס","userId":"13289845640477726640"}},"outputId":"8cfd45c5-9c39-48cb-b683-4c1bcfdb271d"},"id":"Svf67dAsLkJe","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["val loss: 1.3524, accuracy: 0.6087, perplexity: 3.8665\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RTz-eDJHMB0q"},"id":"RTz-eDJHMB0q","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1a8f049017cd45179b5908869bb8d1b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8ecd89f92f4db880a8bbc44a49a068","placeholder":"​","style":"IPY_MODEL_c3dbf5d9a7b140f2b18599b86f6d046c","value":" 80/80 [01:23&lt;00:00,  1.30it/s]"}},"1c1d3e51d33e4aa18acae92a5fbf5352":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e8ecd89f92f4db880a8bbc44a49a068":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cecdc8a0cf24c9f9203905976159e42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e0869168934d9aba17640641f801d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3dbf5d9a7b140f2b18599b86f6d046c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c49b1c25f7b44b14a2fc7922e9950bed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef5873517074452486fc197c90da66e9","IPY_MODEL_e8fdffe37594482e8bd1aa930dc0a586","IPY_MODEL_1a8f049017cd45179b5908869bb8d1b5"],"layout":"IPY_MODEL_8cecdc8a0cf24c9f9203905976159e42"}},"c86f59e6cb53488d8ad2ce005c826b04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7a7dbcaba764b7181dccf8383efa4cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8fdffe37594482e8bd1aa930dc0a586":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7a7dbcaba764b7181dccf8383efa4cf","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2e0869168934d9aba17640641f801d4","value":80}},"ef5873517074452486fc197c90da66e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c86f59e6cb53488d8ad2ce005c826b04","placeholder":"​","style":"IPY_MODEL_1c1d3e51d33e4aa18acae92a5fbf5352","value":"Loading dataset shards: 100%"}}}}},"nbformat":4,"nbformat_minor":5}